[
["index.html", "The Carpentries Curriculum Development Handbook Preface", " The Carpentries Curriculum Development Handbook Erin Becker and François Michonneau 2019-06-10 Preface This is work in progress. Comments and suggestions are welcome either as: an issue or a pull request on the GitHub repository or using hypothes.is "],
["conceptual-elements.html", "Chapter 1 Conceptual elements 1.1 The Carpentries mindset for curriculum development 1.2 Backward design 1.3 Creating a narrative and selecting a dataset 1.4 Limitations of our approach 1.5 The structure of our curriculum 1.6 Collaborative lesson design", " Chapter 1 Conceptual elements 1.1 The Carpentries mindset for curriculum development Carpentries curricula are developed based on the results of research in the science of teaching and learning. We rely on findings synthesized in the book How Learning Works: Seven Research-Based Principles for Smart Teaching (Ambrose et al. 2010). We use this text in our Instructor Trainer training program, so that Trainers (who teach our Instructor Training courses) can understand why we teach the way we do, and why our lessons are designed the way they are. The authors identify seven principles of learning (direct quotation from the book are bolded): “Students’ prior knowledge can help or hinder learning.” – Identifying what the learners know before coming to our workshops help us adjust what we teach. One way we do this is through our pre-workshop surveys. We also give the learners frequent exercises (or “challenges”) throughout our lessons, which help Instructors and learners identify and correct misconceptions. “How students organize knowledge influences how they learn and apply what they know.” – Human working memory is limited, and can only handle about five to seven separate items of information at a time. We organize our lessons to introduce a few concepts at a time, and then provide challenges to give learners an opportunity to practice using these new concepts. This lets learners build connections between new concepts and their previous knowledge and transfer this new knowledge into their long-term memory, increasing the likelihood that they will be able to use this information successfully in new contexts. “Students’ motivation determines, directs, and sustains what they do to learn.” – Our learners come to our workshops already motivated to learn the concepts we teach. They realize they need the skills we teach to conduct their research more effectively. They have experienced the pain that comes with copying and pasting data across spreadsheets, or having to re-do complex graphs over and over as new data come in. However, they may also be intimidated by how much they have to learn before being proficient programmers and data analysts. Two strategies we use to keep our learners motivated are: (1) to create a positive learning environment, and (2) to teach the most useful skills first. We teach both of these in our Instructor Training program, and discuss how they influence curricular design below. “To develop mastery, students must acquire component skills, practice integrating them, and know when to apply what they have learned.” – Our lessons use frequent challenges to provide opportunities for learners to practice applying their new skills. These challenges are designed to incrementally build on each other and integrate previously taught and new skills. Careful attention to exercise design helps assure learners will be able to transfer the skills they acquire in our workshop to their own research. “Goal-directed practice coupled with targeted feedback enhances the quality of students’ learning.” – When Learners try to solve the challenges we include in our lessons, they receive direct feedback from the computer - either an error message or the expected answer. Error messages are often opaque, and do not on their own help learners advance in their learning process, making them frustrated and demotivated. Our lessons are designed to be delivered as real-time in-person instruction, so that learners get feedback from Instructors and workshop helpers that is human-parsable and directed to their level of understanding. Furthermore, challenges used in a lesson should only require the skills that have already been introduced during the workshop, and should have a limited range of possible answers. “Students’ current level of development interacts with the social, emotional, and intellectual climate of the course to impact learning.” – Providing a positive learning environment reduces learners’ stress and helps increase their confidence in their ability to use the skills we teach. Creating this positive environment is a responsibility shared among all participants: Instructors, helpers, workshop hosts, and learners. Setting expectations by introducing our Code of Conduct at the start of each workshop, and enforcing it, contributes to making the workshop a welcoming space for everyone. Other strategies we use to create a positive learning environment are covered in our Instructor Training. Curricular content also plays a major role in creating a positive environment: examples chosen should not be alienating, skill level must be appropriate for the audience, and the examples and challenges must be directly applicable for our learners. For instance, when a learner creates a visualization that they can directly apply to their own data, it reinforces their motivation and favors a positive learning climate. “To become self-directed learners, students must learn to monitor and adjust their approaches to learning.” – In-person workshops allow Instructors to model the thinking process that is needed to address the challenges in our lessons. As an Instructor, being very explicit (“thinking aloud”) about the steps of the mental model that are involved in identifying the functions to use, the values of the arguments they take, and the order in which to call these functions to solve an exercise, helps learners to think of the questions they need to ask themselves when facing new problems to solve. While this type of approach works for any level of complexity in the challenges we teach, it works best for the most advanced ones, where several steps need to be integrated to come to the solution. Before reaching this level of complexity, the challenges can be designed to guide this process, using scaffolding. Scaffolding is the process of providing support to a learner while new subjects and concepts are introduced. Scaffolding assists learners as they progress through increasingly complex code creation by breaking the complex code into smaller, more manageable chunks. Common parctice problems used in instructional scaffolding are Parson’s problems, where all the pieces of code to answer the problem are already written but are not in the correct order; and, fill in the blanks. Instructional scaffolding might be one of the most important things we use in our workshops. It sets learners on a successful path for further self-directed learning. When developing the content of the curriculum, think of the kind of thinking process that is needed to successfully address the research questions in your field. Applying these principles effectively requires that they are incorporated into both what is taught (content) and how it is taught (delivery). Our Instructor Training program focuses on teaching Instructors how to use these principles in their teaching. In this handbook, we focus on applying these principles to curriculum design. Before starting to create lesson content, we highly recommend that you familiarize yourself with our Instructor Training curriculum. 1.2 Backward design Backward design is an instructional design model that starts with identifying the desired outcomes of a learning experience, including core skills and concepts that learners need to acquire. These identified outcomes are used to develop course content and assessments to measure learners’ progress towards these outcomes. This model was developed by Grant J. Wiggins and Jay McTighe in the late 1990s and is expanded on in their text Understanding by Design. We use backward design in developing our curricula because of its focus on identifying clear, measurable learning goals and providing assessments aligned with those goals. In essense, the backward design process has three stages: Identify the practical skills we aim to teach. Design challenges to give an opportunity for our learners to practice and integrate these skills. Identify what we need to teach for our learners to acquire these skills. This approach ensures that all the skills we teach work together to meet the over-arching goals of our curriculum. It also reduces the risk that we won’t teach a concept learners need in order to be able to master the skills we aim to teach. Similarly, it avoids teaching topics that do not help us (and our learners) meet our goals. Reducing distractions is part of our lesson design as we strive to reduce cognitive load on learners. To this end, we also develop our lessons to be centered around a narrative and a dataset they can relate with quickly. Because our workshops are domain-specific, the data we use, and the type of questions we ask with the data are already somewhat familiar to our learners. Their energy and focus can be directed towards learning the skills we teach rather than on getting familiar with data and concepts that are foreign to them. This strategy also increases the motivation of our learners. By learning how to solve problems that are familiar to them, they can more easily transpose these skills directly to their own data, and have a good starting point to continue their learning process as they try to solve new or more complex problems with their own data. 1.2.1 Identifying the practical skills Our primary aim in a Carpentries workshop is to increase the confidence of our learners. We want to demystify and make accessible the process of computing and analyzing data. More than a third of learners at our workshops have little to no coding experience (Jordan, Michonneau, and Weaver 2018). Our workshops provide them an opportunity to try, in a friendly environment, something they perceive as intimidating. Another important goal is to make the research life of our learners easier. We emphasize teaching “good enough practices” (Wilson 2017) - concrete skills that are accessible, able to be adopted by researchers of any skill level, and likely to make an immediate positive impact on learners’ work. Teaching defensive programming, how to use spreadsheets effectively, or how to organise files consistently across research projects, are practical skills that can save a lot time when learners apply them in their own research. When developing a new curriculum, the first step is to identify the skills that will be the most immediately useful to learners and have the biggest impact on their work. This will vary a lot, so having a clear idea of your lesson’s intended audience is critical at this stage. We will discuss in detail the process of defining your audience and identifying these core skills for your lesson in a later chapter. 1.2.2 Designing challenges to assess understanding Once you have identified these high-impact skills, the lesson content should be designed to create frequent opportunities for learners to practice these skills while exemplifying the tasks they perform in their daily work. Live coding and hands-on challenges that learners can directly relate to should allow them to envision how they can start using the skills taught with their own data as soon as the workshop is over. In traditional Western instruction, learners are presented with new material during course time and then sent home to practice applying the concepts learnt on their own. A major limitation of this approach is that learners often encounter difficulties in trying to apply their new knowledge or skills and need to troubleshoot on their own, without support. Education research shows that novices learn best when they are given feedback and coaching in real time while practicing their new skills (see principle number 5 above) so that errors are corrected and mis-steps redirected before mistakes have a chance to become discouraging or engrained in learners’ memory. To this end, Carpentries workshops are designed to provide frequent opportunities for learners to practice new skills. To be helpful in providing useful feedback, these challenges need to both a) be narrowly targeted to the skills that have been taught (i.e. not to depend on untaught concepts) and b) be diagnostic (Instructors should be able to tell what the learner is misunderstanding based on how they answer the question). The practical aspects of creating useful challenge problems is discussed in a later chapter. 1.2.3 Planning the content of the lesson After deciding on a list of core skills your learners need, and creating a set of well-targeted, diagnostic exercises, you can then start to create the bulk of the content for the lesson. This material can be thought of as the “script” for the instructor to follow while teaching and should be planned very carefully to complement the exercises you’ve already designed. We cover the process of creating curricular content in a later chapter 1.3 Creating a narrative and selecting a dataset Because we strive to provide a realistic experience for learners that is as similar as possible to the workflow they would use in their own work, our lessons use real data and are structured in a natural flow that corresponds to how a learner would experience working with their data in real life. For many curricula, this means starting with a lesson on data organisation and progressing through data cleaning, analysis, and visualisation or reporting. It is important to choose a dataset that is an authentic representation of what your audience would encounter in their day-to-day work. The practicalities of chosing an appropriate dataset are covered in a later section of this handbook. 1.4 Limitations of our approach Learners can’t go from complete novices to experts in two days (or in the course of any single class). We aim to provide learners with three things: A set of foundational concepts and skills; A mental model that connects those concepts into a useful framework and that can be built upon in their future learning; and The motivation and skillset they need to continue learning past the end of the workshop. Managing learners’ expectations, and clearly communicating to them what they will (and won’t) be able to do by the end of the workshop, is important because it limits the chance of demotivation. 1.5 The structure of our curriculum 1.5.1 The elements of The Carpentries curriculum 1.5.1.1 Episodes An episode is a single block of content and renders as a single page of a lesson website. Each episode teaches a set of related concepts (for example, navigating files and directories or indexing and subsetting data). It lists measurable learning objectives related to those concepts and contains a number of challenges to assess learners’ ability to perform those learning objectives. Episodes within a lesson can be dependent on earlier episodes and are generally taught in sequence. 1.5.1.2 Lessons A lesson is a collection of episodes that together help the learner to develop a particular set of competencies (for example, version control or data organization). Each lesson has a landing page that lists all its episodes as well as the overall learning objectives. The overall learning objectives for the lesson should be met by its episodes. Assessment of lesson-level learning outcomes is summative and can be addressed with a post-workshop survey. Lessons can be used independently and should not rely on concepts from other lessons. Lessons may have optional episodes, but lesson designers should provide a recommended structure or structures for what episodes should be taught together and in what order. 1.5.1.3 Curricula A curriculum is a set of lessons that together teach skills needed in a particular domain (for example, genomics or geospatial research). A curriculum has a landing page listing its component lessons and overall learning objectives, and describing the data used in the curriculum. Carpentries curricula often have a narrative structure, where lessons are explicitly linked in a sequence, for example, as steps in a data handling workflow. 1.5.1.4 Lesson Collections A lesson collection is the full set of lessons housed within a specific Lesson Program (for example, all Software Carpentry lessons), or within The Carpentries organization (including our Instructor Training and Trainer Training lessons). Lessons within a collection should match the target audience of the Lesson Program or the broader Carpentries community. 1.5.2 The I-We-You model Gradual release of responsibility Thinking aloud (I do) Provide scaffoding (We do) – think-pair-share, use this to identify misconceptions During the you do, move around, ask for their thinking aloud, listen to their thinking, identify misconceptions. Limitations teach to the mean. 1.6 Collaborative lesson design We transpose the model of open-source software development to collaborative lesson development The open source model of development adapted for lesson Collaborative lesson development. Writing lessons for others to use References "],
["deciding-what-to-teach.html", "Chapter 2 Deciding what to teach 2.1 Target audience 2.2 Skills list 2.3 Example using a Software Carpentry Learner Profile", " Chapter 2 Deciding what to teach As discussed in an earlier chapter, the first step in designing a curriculum according to backward design principles is to identify the practical skills that you aim to teach. This step is absolutely critical to defining the scope of your curriculum and to avoid scope creep, both during initial writing of the lesson materials and later community-driven development. 2.1 Target audience To identify the skills you aim to teach, it is first essential to define your target audience, as different audiences will have different needs, as well as different starting skill sets. For example, Data Carpentry’s Genomics workshop curriculum assumes that learners have some background in the biological sciences and will understand biological terminology and abbreviations used in those lessons, but does not assume any prior experience with the tools taught in the lesson, including The Unix Shell and Amazon Web Services. These assumptions set the stage for lesson development, by placing boundaries around what will and won’t need to be explained in the lesson. Defining your target audience is also essential to reducing the impact of expert blind spot. As an experienced researcher in your field, there are likely many steps in the data management and analysis process that you do without consciously thinking about. Without explicitly evaluating your target audience and understanding their actual background and skill level, you are in danger of skipping over intermediate steps that they need to know in order to succeed in their research. You probably already have some sense of your target audience. To help refine this sense, ask yourself the following questions. Write down your answers and see if you can clearly articulate who is and isn’t included in your audience. Share these thoughts with your colleagues and see if they agree. 2.1.1 Audience definition questions What is the expected educational level of your audience? – Do you expect most learners to be undergraduate students, graduate students, or to have completed graduate school? If you are targeting graduate students, do you expect learners to be new graduate students, masters degree holders, or doctoral candidates? What type of exposure do your audience members have to the technologies you plan to teach? – Think about the typical course work that someone in your field has completed when they are at your targeted educational level. Have they had classes where they needed to use R, Python, or some other programming language for their homework? Does your department require any courses on data organization or management? Do students in your field ever interact with a remote computing system? Don’t worry if the answer to all of these questions is “no”, most university departments don’t build computational training into their undergraduate or graduate programs - which is why The Carpentries exists! Talk with others in your field, especially colleagues at different institutions and in different countries. Having an accurate picture of your target audience’s actual exposure to these skills will help you plan a realistic curriculum. What types of tools do they already use? – Related to the previous question, it is useful to understand the toolkit that your target audience is already comfortable with. Do they commonly use spreadsheet software like Microsoft Excel, Numbers, or Google Sheets? Are they most comfortable working in rich text editors like Microsoft Word or Google Docs? Do they use any web-based GUIs or databases? Having this information will help you appropriately target your content by making useful analogies and tying new knowledge to existing knowledge. It is also very important to understand what tools established researchers in the field are using. No matter how enthusiastic a new doctoral student might be about using Python, if everyone else in their lab (including their advisor) uses MatLab, they’re unlikely to be successful in convincing the entire lab to change their workflows. What are the pain points they are currently experiencing? – The Carpentries trainings are designed to meet learners where they are and help them improve their workflows in a way that is immediately useful for them. We avoid idealism in favor of realism. Yes, it would be excellent if use of version control was standard across the research community, but if the learners at your workshop don’t see the immediate benefit of version control, they are unlikely to implement it. Talk with students and other new researchers in your field. What are the computational tasks they spend hours upon hours doing, only to have to redo when they get their reviews back from the publisher? What repetitive tasks do they do by hand and find mistakes in weeks or months later? People love to share stories like this and you can learn a lot about what others in your field are struggling with by collecting these stories. These are the skills you should be targeting in your lesson. What types of data does your target audience work with? What are the commonalities in the datasets your target audience will encounter? (types of variable, size, standard data formats, etc.) - If you’re designing a domain-specific curriculum, you’ll need to consider the range of data types that members of your domain community work with. For example, researchers in the social sciences work with a wide range of data types, but survey data is common in this research community. Data Carpentry elected to develop lessons around closed-ended survey data, with the hopes of expanding this lesson set to include analysis of free-response text in the future. Similarly, a genomics researcher may work with data sets that span multiple species or multiple individuals or populations within a species. The Data Carpentry Genomics curriculum development team chose to focus on intra-species data sets. Researchers in the field who work with different data types will still be able to benefit from the lessons, but choosing a common data type will ensure your lesson is maximally useful for a broad component of your domain community. It is important to make this decision early on, as trying to include every type of data that researchers in your field work with will result in sprawling, ungainly lessons that aren’t useful for anyone. Choose one thing and do it well! 2.1.2 Learner profiles After thinking through the audience definition questions above, and discussing these questions with colleagues in other institutions, you should have a fairly clear understanding of your target audience. You should now know who you expect to show up to your workshops, what knowledge and expectations they will bring with them, and what their motivations are. Keeping this information front-and-center throughout the lesson development process is incredibly important, as it is all too easy to forget your target learner and go down tangents in your lesson that don’t serve this set of learner’s needs. To make your target audience more concrete, we recommend creating a set of learner profiles. A learner profile describes a fictional learner at your workshop and includes the person’s general background, the problems they face, and how the course will help them. Software Carpentry has example learner profiles that will be useful in developing learner profiles for your own course. We recommend creating 2-4 learner profiles that describe different segments of your target audience. These profiles can then be consulted at future stages in the curriculum development process. For example, when developing an exercise, you can look at your learner profiles and ask “Is this exercise useful for my target learners?”. 2.2 Skills list Congratulations! You now have a solid understanding of the users of your lesson materials and can concretely define the background knowledge and goals of your learners. These goals are a combination of a) reducing or removing pain points that your learners can self-identify and b) achieving next-level competencies that learners may not realize are possible, but which will be practically useful to them in their research. You can think of these two components as the starting and ending points for your lesson. The background knowledge and skills that your learners bring to the workshop define the starting point, while your learners’ goals define the end point. With these start and end points, you can now define the list of skills that you will need to teach at your workshop. 2.3 Example using a Software Carpentry Learner Profile The following example illustrates how a learner profile can be used to define a list of concrete skills. Example of Learner Profile Fan Fullerene is a graduate student in chemistry who is working as a lab technician to help cover his family’s living costs. His only programming experience is a general first-year introduction to computational science using Python. Fan’s supervisor is studying the production of fullerenes (also known as “buckyballs”). Each set of experiments involves testing a sample at 20 different temperatures and 15 different pressures. Using a machine borrowed from a collaborating lab, Fan can run all temperature and pressure combinations in one job, but must upload a parameter file to the machine to do this. The temperatures and pressures to be used vary from sample to sample, so Fan now has two dozen different parameter files, each containing 300 lines of control information that he fervently hopes is correct. The machine sends these files to Fan once the experiment is completed. Fan analyzes them by opening Excel, copying and pasting the data into a spreadsheet, then creating a chart using the chart wizard. He then saves the chart as a PNG file on the group’s web site, along with the original data file. Fan and his wife have had two children arrive while in graduate school, and his research progress is behind that of his peers. He is very nervous about finishing his PhD and suffers from undiagnosed depression. Software Carpentry will teach Fan how to write programs to generate parameter files and analyze experimental results, and how to track the provenance of the data he is working with so that scientists can trace backward from the final charts to the raw data they represent. It will also teach him how to use version control systems to manage changes to his code. Fan’s background knowledge and skills include: maybe some vague recolection of basic syntax and terminology from his Python course use of Excel to process tabular data and create graphics interaction with a web GUI to upload data to his lab’s website Fan’s goals include: creating parameter files automatically managing his many parameter files efficiently automating analysis for multiple runs of his experiment quickly and easily creating a specific graphic from his data uploading data and results to his lab’s website An (incomplete) list of target skills that can be extracted from this information includes: writing for loops (to create parameter lists) writing data to a file (e.g. parameter lists) writing reusable scripts creating a specific type of graphic programmatically customizing graphics to label them appropriately for a particular data set creating a version controlled repository for storing his parameter and output files pushing output files to his lab’s website programatically It is important at this stage to be sure you are defining skills that your learners will acquire, not topics that you will teach. You may be tempted to say, for example, that learners will learn about the grammar of graphics – which places the emphasis on a topic that learners will learn about - or that they will learn how to use the R package ggplot2 – which emphasizes the tool that learners will be exposed to. Neither of these ways of stating the learning goal focuses on the abilities that learners will develop that will help them in their work. Since you, as the lesson developer, will be using this skills list to create exercises and lesson content, it is essential to describe specific competencies and abilities that the content will help learners to develop. For example, this learning goal would be better phrased as “create plots that can be quickly and reproducibly modified and customized.” If your target audience has specific plotting needs (like creating time-series plots, or visualising very large datasets), this learning goal would be phrased to incorporate those specific needs. Spend as much time as you need to on defining this skills list. Don’t rush it! This list will drive the rest of the curriculum development process. It’s ok if your initial list needs to be modified later, but it’s well worth the time to make this list as complete and concrete as possible now as it will save time in the remaining steps. "],
["designing-challenges.html", "Chapter 3 Designing challenges 3.1 Picking a dataset 3.2 Formatting the dataset for teaching 3.3 Designing challenges 3.4 Different types of challenges", " Chapter 3 Designing challenges Now that you have a list of the concrete skills that your learners will develop in your workshop, it’s time to start the second step of backward design - designing the challenges that you will use to help your learners practice those skills. These challenges will also enable the instructors to evaluate learner’s skill progression in real time and re-direct their teaching as needed. Carpentries workshops use real-world data to increase the immediate applicability of our lessons and to reduce cognitive load for the learner. The first step towards developing the exercises you will use in your lessons is to select an appropriate dataset. 3.1 Picking a dataset The dataset is a critical element of a Carpentries lesson. It needs to be chosen carefully and to meet the following criteria. Use a single dataset – Curricula are domain-specific and the same dataset should be used across all lessons that are part of the same curriculum. When developing a standalone lesson (one that is not part of a curriculum), we encourage you to choose a dataset that is already in use in one of our existing curricula. Although each lesson should use the same dataset, it is often appropriate to use variations of the core dataset for different lessons within a curriculum. For instance, the Data Carpentry lessons on data organization with spreadsheets use messy spreadsheets that have been created from the original dataset, but which introduce formatting issues to teach tidy data principles. Whenever possible, these derived datasets should be created using scripts rather than manually, so they can be regenerated if the original dataset changes. The dataset should be released under a CC0 license – Copyright laws and laws governing use and sharing of data and databases vary among countries. The Creative Commons Zero (CC0) license is designed to allow unrestricted use and sharing of data universally. The CC0 license allows the development of lessons around the dataset and modification of the dataset to suit our teaching needs. The dataset should be deposited in a public repository – All variations of the dataset that are used in the lesson should be deposited. The Carpentries deposits data for our lessons on figshare. If you choose another option, make sure the repository where the data is archived has the following features: a DOI link pointing to an overview of the dataset pre-registration of the DOI all files can be downloaded directly as an archive (e.g., zip file) with a persistent link each file can be downloaded directly with a persistent link the repository supports versioning The dataset should be real and represent what researchers in the field encounter – The datasets used as examples in the lessons should be based on real research datasets, and be of sufficient complexity that they are representative of the type of dataset that learners would encounter in their own research. Authors of the dataset should be identifiable, acknowledged, and there should be a link to the original source for the data – Even though the datasets we use in our lessons are released under a CC0 license, we acknowledge the authors of the dataset and link to the research projects based on the data we use. The dataset should be large enough – Analysing the dataset should represent a real challenge that highlights the power and usefulness of the tools covered in the lessons. The dataset should be larger than what would be easy to analyze and manipulate in a spreadsheet program. It should be similar in size to what researchers in that domain work with in their actual research. For instance, the core dataset for the Data Carpentry Ecology curriculum has ~35,000 rows. The dataset should be complex enough to ask interesting questions – Each observation should have at least 4-5 variables. These variables should be of a few different data types (at least continuous, discrete, integers, real numbers; and depending on the domain, may include more specialized data types such as date/time, GPS coordinates, unstructured text, etc.) The motivation for study and the protocol for data collection should be understable without much context – We have limited time in our workshops to cover the technical skills we want to teach. It should not take long to explain to learners what the data is about, how it was collected, and what types of interesting questions can be asked from it. The dataset should be relevant in different geographical and cultural contexts – Our workshops are taught to learners from diverse cultural and geographical backgrounds. The dataset should be understandable without much cultural context or pre-requiste knowledge needed to make it compelling. There should be clear and comprehensive metadata – The metadata should include a description of the data, explain what is included in each data field, how it was measured, and the unit in which it is reported. Overall, datasets used in Carpentries workshops should serve as examples of publicly deposited data suitable for research re-use. Learners should be able to use these datasets as examples and guides for their own research data that they would like to publish and make available to the broad scientific and academic community. 3.2 Formatting the dataset for teaching A possible challenge when using research datasets for teaching is that the dataset can include complexity that makes teaching more difficult by unnecessarily increasing learners’ cognitive load. While it is important for the dataset to provide an authentic experience for learners, it is often useful to simplify it or do some initial data cleaning and wrangling to make it easier for learners to focus on the core skills you are teaching. For instance, you may want to edit the dataset so that missing values are parsed appropriately. You may also want to remove data which leads to errors or warnings during parsing, columns with data types that are not relevant for the learning objectives of the workshops, or variables which require additional context to understand. When preparing a dataset for teaching, aim to find a balance between providing an authentic experience for learners while keeping complexity low to limit distractions from the learning objectives. Depending on the lesson’s goals, it might also be interesting to include several versions of the datasets that have undergone various levels of processing. At the beginning of the lesson, you can provide a clean and well organized dataset, while later you can introduce more complexity and teach learners how to handle it to generate the cleaner version of the data. Don’t introduce too many (no more than three) versions of the dataset in your lessons, as dealing with many files and remembering their differences can become challenging for the learners. 3.3 Designing challenges Once the dataset is in place, you can start to design challenges that provide learners an opportunity to practice the skills that you’ve included in your skills list. Writing the challenges before writing the content of the lesson ensures that the lesson will remain focused, and can reveal gaps in your skills list. The challenges in a lesson should be a mixture of direct application challenges and synthesis challenges. A direct application challenge is a straightforward implementation of a concept that learners have just been exposed to, while a synthesis challenge requires learners to integrate recently learned skills with skills that were covered earlier in the lesson. Learning is reinforced when Instructors explicitly point out how the skills seen in earlier parts of the lesson are being integrated to solve the challenges. Challenges in Carpentries lessons are a form of formative assessment. They help learners further their learning by having a chance to put into practice the skills being taught. They also help Instructors monitor the level of understanding in the classroom, and potentially catch misconceptions in the learner’s mental models that can be corrected in real time, before they become ingrained. When starting to design challenges, it is helpful to start by planning the last exercise of each episode. This will help you keep the big picture in mind and ensure that the rest of the exercises you develop lead up to this larger goal. These final challenges are also the most likely to be “unscaffolded”, and so are easier to develop without detailed knowledge of the various types of exercises discussed later in this chapter. So you can go ahead and draft those final challenges now before reading the rest! 3.4 Different types of challenges There are many different types of challenge questions that can be developed. In this section, we introduce a few common types of challenges, in order of increasing difficulty (for the learner). When planning your exercises, keep in mind that you will need at least one exercise for every 10-15 minutes of instruction (and more is better!). To quickly estimate how many exercises you need to develop, divide the number of minutes of total delivery time (the number of minutes your learners will be in their seats) by 20. For example, a two hour lesson needs around six exercises. As a rough estimate, plan 8 minutes for each exercise (including discussion of the solution and questions) and 12 minutes of instructional time between exercises. 3.4.1 Multiple Choice Questions Multiple choice questions (MCQs) can be a useful tool for formative assessment if they are designed such that each incorrect answer helps the Instructor to identify learners’ misconceptions. Each incorrect answer should be a plausible distractor with diagnostic power. “Plausible” means that an answer looks like it could be right, and “diagnostic power” means that each of the distractors helps the instructor figure out what concepts learners are having difficulty with. For example, if learners are learning about subsetting data in R with the dplyr functions filter() and select(), you might ask them to determine which of the following code blocks will return only the values of the “Species” and “Petal.Width” variables and only for observations of the “setosa” species where petal length was greater than 1.5. iris %&gt;% filter(Species == &quot;setosa&quot; &amp; Petal.Length &gt; 1.5) %&gt;% select(Species, Petal.Width) This is the correct answer. iris %&gt;% select(Species == &quot;setosa&quot; &amp; Petal.Length &gt; 1.5) %&gt;% filter(Species, Petal.Width) Learners who select this answer have a simple factual misconception. They’ve confused the select() and filter() functions. They need to be reminded that filter() is for subsetting by row and select() is for subsetting by column. iris %&gt;% select(Species, Petal.Width) %&gt;% filter(Species == &quot;setosa&quot; &amp; Petal.Length &gt; 1.5) Learners who select this answer have a conceptual misunderstanding that will may require more time and effort to correct. They haven’t understood that the pipe (%&gt;%) character only passes into the next command the output of the previous command, and nothing else. Since they have used the select() function first, the “Petal.Length” column is no longer present in the output and cannot be used for comparison. This misconception might be addressed by drawing a diagram and walking through what the data looks like at each step of the command. Another follow-up question using the same skills could then be used to assess whether learners have understood the concept. As illustrated above, formative assessments are most powerful when an instructor modifies their instruction depending on the results of the assessment. An instructor may learn they need to change their pace or review a particular concept. Knowing how to respond to the results of a formative assessment is a skill that you will develop over time. Making sure your assessments are designed to test only one or two concepts at a time will help ensure that the feedback is useful. The process of developing diagnostic plausible distractors takes time and requires some knowledge of what common misconceptions are for a particular topic. This knowledge can come through teaching experience (yourself or others’) and is sometimes formally defined through concept inventories. One strength of The Carpentries community is that our lessons are taught over and over again by different Instructors in different teaching contexts. Some of those Instructors give feedback on challenges and misconceptions that their learners had. Our exercises are thus continuously improved by pooling the teaching experience of our 1,500+ strong Instructor community! 3.4.2 Parson’s problems One reason well-designed multiple choice questions are so useful is that they constrain the problem space. Learners don’t need to worry about all of the details of syntax and how to spell all of the variable names, but can focus on just the concepts that the exercise author intended them to focus on. Another type of formative assessment that provides this benefit are Parson’s problems. A Parson’s problem is an exercise where learners are given a set of items (in our case, lines of code) and asked to put them into an appropriate order to accomplish a specific task. The MCQ example given above could be formulated as a Parson’s problem: filter(Species == &quot;setosa&quot; &amp; Petal.Length &gt; 1.5) %&gt;% iris %&gt;% select(Species, Petal.Width) A more difficult version of a Parson’s problem might include lines that are not part of the solution (distractors): filter(Species == &quot;setosa&quot; &amp; Petal.Length &gt; 1.5) %&gt;% filter(Species, Petal.Width) iris %&gt;% select(Species, Petal.Width) select(Species == &quot;setosa&quot; &amp; Petal.Length &gt; 1.5) %&gt;% If this is the case, make sure learners know that not all of the code chunks need to be included in their answer! Parson’s problems are somewhat less structured that MCQs, which makes them slightly better for preparing learners to tackle similar problems in their own work. However, this also makes it more difficult for Instructors to diagnose learner misconceptions and adjust their teaching accordingly (because there are more possible responses). As will all of the challenge types we will discuss in this chapter, MCQs and Parson’s problems can be used in combination to provide learners with both structure and appropriate levels of challenge. 3.4.3 Fill-in-the-blank problems Fill-in-the blank problems can be thought of as the next level of decreasing structure after MCQs and Parson’s problems (although this depends on the number of lines in the Parson’s problem and the number of possible choices for filling in the blanks, among other factors). The following challenge (from the Software Carpentry lesson on The Unix Shell) illustrates one possible application of fill-in-the-blank problems: Challenge: Moving to the Current Folder After running the following commands, Jamie realizes that she put the files sucrose.dat and maltose.dat into the wrong folder: $ ls -F analyzed/ raw/ $ ls -F analyzed fructose.dat glucose.dat maltose.dat sucrose.dat $ cd raw/ Fill in the blanks to move these files to the current folder (i.e., the one she is currently in): $ mv ___/sucrose.dat ___/maltose.dat ___ Solution $ mv ../analyzed/sucrose.dat ../analyzed/maltose.dat . Recall that .. refers to the parent directory (i.e. one above the current directory) and that . refers to the current directory. We can also apply this concept to our earlier example and ask learners to fill-in-the-blanks to build a code block that will return only the values of the “Species” and “Petal.Width” variables and only for observations of the “setosa” species where petal length was greater than 1.5: iris %&gt;% filter(Species ___ &quot;setosa&quot; &amp; ___ &gt; 1.5) %&gt;% select(Species, ___ ) The difficulty of a fill-in-the-blank problem can be adjusted by changing the number of blanks, and by providing (or not providing) a “word bank” of options to use. You can even use a series of similar fill-in-the-blank problems, increasing the number of blanks each time, to prepare learners to build a code chunk without scaffolding. When used in this way, fill-in-the-blank problems are also called faded examples. We discuss the use of faded examples, and why they are a useful tool, in more detail in our Instructor Training course. 3.4.4 Use the concept in a different context Once learners have had an opportunity to practice using a concept in the same context as it was originally taught (direct application challenges), it’s time to stretch their understanding by asking them to apply the same concept in a different context. This adds realism and makes learners better prepared to apply these concepts to unique problems in their own work. This type of exercise will often require learners to proactively look up help files or do a Google search. For example, in the Data Carpentry lesson Data Analysis and Visualization in Python for Ecologists, plotting is taught using the plotnine package. That package implements the grammar of graphics developed by Leland Wilkinson, which includes the concept of a plot’s geometry. Different plot types have different underlying geometries that interact differently with other plot parameters. In this lesson, learners are led through an example where they create a scatterplot (using geom_point()) of weight versus an animal’s hindfoot length. surveys_plot = p9.ggplot(data=surveys_complete, mapping=p9.aes(x=&#39;weight&#39;, y=&#39;hindfoot_length&#39;)) surveys_plot + p9.geom_point() They are then asked to create a barchart showing the number of observations in each region (or “plot”) of the field site. Challenge - bar chart Working on the surveys_complete data set, use the plot-id column to create a bar-plot that counts the number of records for each plot. (Check the documentation of the bar geometry to handle the counts) Answers (p9.ggplot(data=surveys_complete, mapping=p9.aes(x=&#39;plot_id&#39;)) + p9.geom_bar() ) To answer this problem, learners need to locate and decipher the appropriate help file (for the geom_bar() function). They also need to change the mapping attribute to apply to “plot_id” rather than “weight” and “hindfoot_length”. Later challenges in this lesson require learners to apply multiple concepts in new contexts, for example, modifying both the plot type and underlying aesthetics like color. These types of problems are incredibly powerful, as they provide the most realistic example we’ve discussed so far of the skills learners will need to be able to apply what they’ve learned to their own work. This also means, however, that these problems are fairly unstructured, and include many more potential areas for learners to get off track. It is also very easy, when designing these problems, to make them more difficult than you intended - either by requiring learners to apply multiple concepts in new contexts or by including new concepts that haven’t yet been covered in the lesson. Be careful, always have your lesson reviewed by at least one novice user if possible, and above all else, be prepared for feedback from Instructors “in the field” about how to improve these (and all of your) challenge problems. 3.4.5 Switch the dataset This is a very advanced exercise type. Information to be added in a later version of this handbook. "],
["developing-content.html", "Chapter 4 Developing content 4.1 Fundamental elements 4.2 Supporting elements", " Chapter 4 Developing content At this point in the lesson development process, you should have a list of the core skills that your lesson will teach, along with a set of exercises that you will incorporate into your lesson. If you’ve taken the time to go through these steps, the remaining parts of the development process will be much more straightforward and take less time than if you try to start with developing content. Its ok if your list of skills and set of exercises changes a little as you develop your lesson content – none of us get it right on the first try – however, if you’ve invested time in the first two steps of the backward design process, these changes should be fairly small. Now that we’re ready to start writing the lesson material, it’s worth laying out some of the fundamental elements of a Carpentries lesson. These elements are covered in much more detail in a later chapter, so we will focus here on the bare minimum you need to know to get started. It’s perfectly ok to work through some or all of the steps described in this chapter before worrying about the logistics of putting your materials up on GitHub, but if you’re working with multiple authors, it may be worth putting your materials on GitHub at this stage, to make collaboration easier. The Technological Introductions chapter can get you started with hosting your lesson on GitHub. 4.1 Fundamental elements The bulk of a Carpentries lesson consists of exercises, example code chunks, and narrative text. You have already developed many or all of the exercises you will include in your lesson, so congratulations on being one-third done with content development! The remaining two major components of the lesson are described below. 4.1.1 Code chunks Carpentries workshops are taught using participatory live coding. Instructors type the code as they teach it and learners type along with the Instructor. For more information about how live coding works, and what its advantages and disadvantages are, read that section of our Instructor Training program. The fact that Carpentries workshops are taught using live coding means that much of your episode content will be code chunks - short blocks of code that learners type along with the Instructor and evaluate on their own machines. Since you already know the structure of your dataset, and already have your exercises in place, it’s fairly straightforward to create the code chunks for your lesson. Starting with the first exercise, make a list of each of the commands and syntax elements that learners need to be familiar with in order to solve the exercise. For example, the first exercise in the Data Carpentry lesson Introduction to the Command Line for Genomics asks learners to: Challenge Use the -l option for the ls command to display more information for each item in the directory. What is one piece of additional information this long format gives you that you don’t see with the bare ls command? In order to solve this challenge, learners need to know the following (in approximately reverse order): That options come after the command (e.g. ls -l not -l ls). How to find the manual page for ls to understand the output. What the ls command does in its bare form. How to navigate to the right directory. How to tell what directory they’re in. How to open the bash shell on their machines. That’s six concepts or pieces of information that learners need to have to answer this challenge! If it didn’t seem that complex to you, please revisit the idea of expert blind spot in our Instructor Training curriculum. With this list, you can now construct the pieces of code that an Instructor will need to walk learners through before this first exercise. Those pieces of code (in the same order as above - the reverse order they would be used in a lesson), are something like: ls -F (or any other commonly used ls option other than ls) man ls (or man cd or man pwd) ls cd pwd Not a code chunk, but a demonstration of how to open the bash shell on the Instructor’s machine. You now have your first set of code chunks corresponding with your first exercise. Put these in reverse order and you’re well on your way to writing your lesson! 4.1.2 Narrative text The narrative text component of the lesson provides a guide for Instructors to use while teaching. It should provide a clear and complete narrative that (in theory) could be used by an Instructor as a script for the lesson. Instructors will not actually be using this text as a script, because they will be responding to the needs of their particular learners in real time, both in terms of the level of detail they go into, and in how they answer questions. However, this text should give Instructors a starting point for explaining the lesson content. This text can also be used by independent learners to work through the lesson materials outside of a workshop setting. Wait to start writing your narrative text until you’re fairly confident about the set of code chunks you’ve written. Any changes to the code chunks will require corresponding changes to the text, which can become time consuming. For the set of code chunks above, we would need to write a short explanation for each step. For example, the narrative corresponding to the ls code chunk in this lesson is: We can see files and subdirectories are in this directory by running ls, which stands for “listing”: ls ls prints the names of the files and directories in the current directory in alphabetical order, arranged neatly into columns. And the narrative corresponding to the man ls command in this lesson is: ls has lots of other options. To find out what they are, we can type: man ls Some manual files are very long. You can scroll through the file using your keyboard’s down arrow or use the Space key to go forward one page and the b key to go backwards one page. When you are done reading, hit q to quit. Narrative text should be as short as possible and should avoid discussion of edge cases or caveats. If there are important caveats, those can be included in a callout box (see the Technological Introductions chapter for formatting details of callout boxes). Only include callouts for cases a significant fraction of your learners will experience in their work. It’s very easy to clutter the lesson and overwhelm learners. 4.1.3 Considering cognitive load You may have noticed that the exercise we dissected above required six pieces of knowledge to solve. This number isn’t random! Cognitive science research has clearly established that human working memory is limited, and can only handle a small number of separate items of information at once. This number is generally considered to be 7 plus or minus 2, but recent research has suggested it may be even smaller. If learners are presented with more than this many discrete pieces of information, they will not be able to keep all those pieces in mind similtanously. Once they have had an opportunity to work with those pieces of information, their brains will create connections that will allow them to store the information in long-term memory and retrieve it as needed. This is why it is essential to include frequent exercises, spread throughout the lesson at regular intervals with only ~5 intervening new concepts. If you find that you need more than about this many code chunks between exercises, you probably need to either simplify your exercise, or add another exercise in between. 4.2 Supporting elements Once you’ve created your exercises and written your code chunks and narrative, your lesson is nearly complete! There are a few remaining elements that support the main episode content by providing a clear outline of content for both learners and Instructors. These supporting elements are learning objectives, key points, and framing questions. When you create your lesson repository from The Carpentries template, there will be sections for you to enter these supporting items for each episode. The template will extract these elements and embed them in the rendered lesson webpage. For details, see the Technological Introductions chapter. 4.2.1 Learning objectives Great news - you’ve already almost completed writing your learning ojectives! The skills list that you developed for your lesson can be easily transformed to learning objectives. Learning objectives are statements that communicate to learners the skills they can expect to gain from the lesson. They should always be framed from the learner’s perspective and use action words. In other words, they should emphasize what a learner will be able to do not what they will know. For example, the first episode of the Data Carpentry lesson Introduction to the Command Line for Genomics includes the following learning objectives: Describe key reasons for learning shell. Navigate your file system using the command line. Access and read help files for bash programs and use help files to identify useful command options. Demonstrate the use of tab completion, and explain its advantages. If you didn’t use action words when creating your skills list, there are many existing resources available that list action verbs associated with different levels of learning (one example). For our purposes, the differences among these levels isn’t as important as using action verbs in defining your learning objectives. When learning objectives are framed in this way, learners should be able to self-evaluate whether they have completed each learning objective and concretely understand what they have gained from the lesson or what they still need to work on. Keeping in mind our discussion of cognitive load above, each episode should have ~5-7 learning objectives. If you have more than that, you should consider splitting the material into multiple episodes. 4.2.2 Key points While learning objectives communicate to learners the skills they should develop by working through each episode, key points summarize the main pieces of knowledge that learners should remember after completing the episode. These should also be limited to ~5-7 items. For the episode we’ve been considering in the Data Carpentry lesson Introduction to the Command Line for Genomics, the key points are: “The shell gives you the ability to work more efficiently by using keyboard commands rather than a GUI.” “Useful commands for navigating your file system include: ls, pwd, and cd.” “Most commands take options (flags) which begin with a -.” “Tab completion can reduce errors from mistyping and make work more efficient in the shell.” The Carpentries lesson template automatically creates a reference page that includes all of the key points for each episode in the lesson. Key points should be specific enough that learners are able to use this reference page as review. 4.2.3 Framing questions The final supporting component for the lesson are the framing questions for each episode. These questions provide a high-level overview of the motivations for learning the lesson content. There should be ~1-3 questions for each episode, which should correspond to questions that your target audience ask themselves about their own workflows. The set of framing questions for the Data Carpentry lesson Introduction to the Command Line for Genomics includes: How can I view and search file contents? How can I create, copy and delete files and directories? How can I control who has permission to modify a file? How can I repeat recently used commands? The lesson template automatically creates an overview page for the lesson, which includes the framing questions for each episode. "],
["community-development.html", "Chapter 5 Community development 5.1 Roles", " Chapter 5 Community development 5.1 Roles Our lessons are intended to be teachable by any certified Carpentries Instructor with the appropriate domain experience and background knowledge. Lessons should also be appropriate for learners at different institutions, and not require specialized local or institutional knowledge. Our lessons attain this broad usability by virtue of being the product of many people at differnt institutions around the world who work together in different roles to create, test, and iteratively improve and update lesson materials. 5.1.1 Lesson Authors A lesson may have one or several initial authors. Authors draft the lesson content, figures, and code and create appropriate challenge problems. Authors should have both appropriate domain experience - working in the same field as the intended audience for the materials, and programmatic experience – regularly using the tools for which they are developing lessons in their own work. From a technical standpoint, authors will also need to be familiar with specific technologies that we use for developing and hosting The Carpentries lessons - including git, GitHub, Markdown, RMarkdown, … But don’t panic! If you’re not comfortable with any or all of these tools, we’ll walk you through what you need to know to use them later in this Handbook. Most importantly, to ensure that lesson materials are consistent with The Carpentries vision and values, lesson authors should be certified Carpentries Instructors or otherwise involved in The Carpentries community. If a group of authors are writing a lesson collaboratively, we recommend dividing lessons up by episode, and having only one author per episode. Clearly defining the learning objectives for each episode will help avoid overlap and ensure the lesson flows smoothly - but it will still be important to have regular checkins with all authors. 5.1.2 Reviewers We know no one is perfect! Lesson materials should be read and tested by at least one person other than the original author before being released for use by the broader community in beta pilot workshops. If a lesson has more than one author, co-authors can review each other’s content. Community members can also serve as reviewers. A reviewer commits to carefully reading and testing all code for a lesson or set of episodes and leaving detailed feedback for lesson authors to correct any errors or other issues found. This feedback is provided as issues and/or pull requests (PRs) in the lesson’s GitHub repository (we’ll explain all of that soon!). Authors modify the lessons based on reviewer feedback to ensure the lesson is bug-free, all code runs as expected, exercises are appropriate and test only the concepts being taught, and in general that the lesson is ready to be delivered to learners in a beta pilot workshop. Don’t worry - this review stage is not the only point at which lessons will receive feedback. Our collaborative lesson development model ensures that Instructors and other community members will continue to engage with the lesson materials at all stages of their development and provide near real-time feedback to keep the lessons in good shape for as long as they are actively being taught! Reviewers do not need to have any particular domain background or tool expertise. In fact, we recommend including reviewers who are complete novices either the tool being taught by the lesson and/or the lesson’s target domain. This can help overcome authors’ expert blind spot. Reviewers should also include people from different geographic regions and cultural and linguistic contexts than the lessons’ authors. If all of a lesson’s authors are based in the UK, for example, there should be at least one reviewer from outside the UK, and ideally from a non-majority English-speaking area. Ensuring that lessons are reviewed by people from a variety of cultural and linguistic contexts helps us to avoid colloquialisms, culturally-specific references, and other issues that might make our lessons less accessible to a global community. You will likely need one or two reviewers for every two hours of lesson content. A four-hour (half day) lesson should have at least two to four reviewers. [Include something about accessibility?] 5.1.3 Lesson Maintainers Lesson Maintainers are essential for the long-term viability of a lesson. As a lesson is taught, new Instructors and learners identify potential places for improvement - whether correcting a typo, simplifying code, or suggesting a significant shift in the narrative of a lesson. Maintainers proactively monitor their lesson’s GitHub repository to make sure that PRs and issues are addressed in a timely manner. Maintainers also play a vital role in communicating with contributors, ensuring that our community lives up to its ideals in welcoming and appreciating contributions from everyone - from first-time contributors to long-time members of The Carpentries community. People acting as Maintainers should be experienced with the tool that is being taught in the lesson, ideally using it daily or weekly in their own work. In addition, they should have experience working in a relevant domain related to the lesson materials and/or experience working with GitHub and the other technologies we use to create and host our lessons (link to that section of Handbook). Each lesson will have at least two Maintainers, and it’s ok for one Maintainer to have domain experience and another to be more comfortable with the technical aspects of lesson maintainence. 5.1.3.1 Maintainer recruitment, requirements and time commitment It’s a good idea to recruit three or four Maintainers per lesson, as some may not complete onboarding or may realize that they don’t have the time to commit to this role. https://docs.carpentries.org/topic_folders/maintainers/maintainers.html# Maintainer onboarding (how to run) https://docs.carpentries.org/topic_folders/maintainers/maintainers.html#maintainer-onboarding Maintainer meetings and skill development / office hours A lesson should have at least two or three trained and active Maintainers before it enters the beta pilot workshop phase. Before that time, lesson feedback and edits will be managed by the lesson authors. 5.1.4 Curriculum Advisors Curriculum Advisors provide high-level oversight, vision, and leadership for a curriculum and guide large-scale updates. Unlike Maintainers, who are responsible for the day-to-day work of keeping lessons stable and teachable, Curriculum Advisors maintain a broader perspective on the state of the field and make strategic decisions about major changes to a lesson, for example, updating the technology being taught to take into account major advances in the field or changing the dataset used in the lessons to appeal to a braoder group of learners. A Curriculum Advisory Committee (CAC) is composed of 5-8 people with significant domain expertise who represent the breadth of the field that a curriculum is intended to reach. For example, the Data Carpentry Geospatial CAC includes researchers in ecology, limnology, environmental sciences, and sociology, along with university staff leading institutional GIS education efforts. Multiple career levels are represented, from PhD candidates at the end of their graduate work, to mid-late career professionals. At least one member of the CAC should be actively teaching in the field, so they can bring a practical perspective about what skills students and early-career researchers need. Lesson Maintainers may also serve as Curriculum Advisors, but most Curriculum Advisors will not also be Maintainers. Curriculum Advisors commit to a minimum one-year term, but may serve multiple terms. A CAC should include members from multiple geographic regions and cultural and linguistic contexts to ensure that the curriculum meets the needs of our global community. A Curriculum Advisory Committee meets virtually approximately twice a year to discuss and make decisions about proposed large-scale changes to the lessons within their curriculum. These proposals may be initiated by community members, including Maintainers, or by members of the CAC. The CAC communicates their recommendations back to the Lesson Maintainers and provides consulation and support to Maintainers in implementing proposed changes. Ideally, a Curriculum Advisory Committee should be assembled in the initial stages of lesson development, before materials start to be drafted. The CAC can then provide high-level guidance, including defining the learning objectives and core content for the curriculum and selecting an appropriate dataset that will speak to a broad group of learners. However, we recognize that lesson development may be part of a grant or other structure with requirements that are incompatible with putting together a CAC at such an early stage. If a curriculum will be included in the official Carpentries lesson stack, there must be a Curriculum Advisory Committee in place at the time of its first publication. The CAC must should regularly for as long as a curriculum remains active. 5.1.5 Beta Pilot Instructors A new lesson or curriculum is often taught for the first time locally at the organization that houses the lesson authors. This can be an opportunity to troubleshoot organizational or technological issues with the lesson, and should certainly be done if resources allow, but is not a sufficient test of the lesson’s broader teachability. It is always easier for the creator of a set of curricular materials to use those materials, but more difficult to communicate all of the relevant details to enable others to deliver the curriculum efficiently. In order to ensure that our lessons are able to be taught by all appropriately experienced certified Instructors, a lesson should be beta piloted at least twice outside of the institution in which it was developed, ideally in two different countries. Because lessons at this stage are expected to still have some technical and flow issues, instructors for these beta pilot workshops should be certified Carpentries Instructors who have previously taught at least two Carpentries workshops. Instructors with this level of experience will be more prepared to troubleshoot issues that arise during the workshop, and more likely to provide useful feedback after the workshop. Beta pilot instructors may be lesson reviewers, Maintainers, Curriculum Advisors, or any Carpentries community member other than lesson authors. In fact, recruiting beta pilot instructors from these areas is likely to be fruitful, as these people are already playing active roles in the lesson and are invested in bringing the lesson to maturity. For two beta pilot workshops, you will need at least four instructors. Feedback from beta pilots - how given and how incorporated How to recruit beta pilot Instructors Onboarding? 5.1.6 Instructors How to onboard existing instructors How to recruit new instructors from the domain When to put these roles in place How many people we need in these roles "],
["technological-introductions.html", "Chapter 6 Technological introductions 6.1 Lesson hosting and rendering 6.2 Using the lesson template 6.3 Working on GitHub", " Chapter 6 Technological introductions Our goal is to make developing and contributing to lessons as simple and accessible as possible. The more people who are able to contribute to a lesson, the more we can harness community knowledge and experience to create materials that are teachable and applicable in a range of learning contexts. We recognize that technology can be a major barrier to contribution, and we are currently working on a major update to our lesson infrastructure to reduce this barrier. This chapter reflects our current lesson infrastructure and describes what lesson authors and other contributors need to know to use The Carpentries lesson template. In the individual sections below, we have noted whether particular technological knowledge will remain necessary or be phased out in upcoming infrastructure updates. What knowledge are we assuming lesson authors will have? What knowledge will this chapter help them gain? 6.1 Lesson hosting and rendering The Carpentries hosts all of our lessons on GitHub. We use a shared lesson template to provide aesthetic and structural consistency across our lessons. Template files for each lesson are rendered into a webpage using Jekyll - a static site generator which is written in Ruby. You do not need to know Ruby or Jekyll to write or contribute to a Carpentries lesson. However, you will need to have these software packages installed on your computer if you want to view your lesson materials locally before pushing them to GitHub. Information about installing Ruby and Jekyll is available in the APPENDIX. 6.2 Using the lesson template Each lesson is made up of episodes, which are focused on a particular topic and include time for both teaching and exercises. A lesson repository (or “repo”) includes one file for each episode, and a set of helper files that are required to build the lesson webpage. Most of these helper files are standardized across all of our lessons and aren’t something that lesson authors or contributors need to interact with. In this section, we will focus only on the files that you are likely to interact with. If you’re interested in the details of how the template is structured, and what each of the files does, these details are provided in APPENDIX. We recommend not spending time learning these details now, as we are in the process of greatly simplifying our lesson template. 6.2.1 Lesson homepage The lesson homepage provides an overview of the lesson, including any prequisites, an introduction to the dataset used, a schedule showing the episodes and the time alloted for each, and any other information learners will need for the lesson. For inspiration to guide you in writing your lesson homepage, check out these examples for Data Carpentry, Software Carpentry, and Library Carpentry. The lesson homepage is built from the index.md file, which is automatically created when you initialize a lesson repository. You will need to add the following to this file: A few paragraphs of explanatory text describing the lesson. One or more .prereq boxes detailing the lesson’s prerequisites, giving an overview of the dataset, and/or calling attention to the lesson’s Instructor notes. The schedule will automatically be included in the lesson homepage based on information present in the episode files. 6.2.2 Episode files The majority of a lessons content is in its episode files. Episode files are stored in the _episodes/ folder within your lesson repo (or in _episodes_rmd/ for lessons written in R). Episode file names must start with a two-digit identifier number (e.g. 01) followed by a short descriptive name, separated by a dash (-). For example 02-loop.md, 03-lists.md. The numeric identifier is used to place your episode files in the correct sequence within the lesson. Episode files are written in Markdown (more on that in a moment) or RMarkdown. 6.2.2.1 Episode headers When your lesson repository is created, it will start out with one pre-made episode file (01-introduction.md). You can use this file as a template for creating each of your episode files, as it provides an example of how these files must be structured. The content of this pre-made episode file is shown below: --- title: &quot;Introduction&quot; teaching: 0 exercises: 0 questions: - &quot;Key question (FIXME)&quot; objectives: - &quot;First learning objective. (FIXME)&quot; keypoints: - &quot;First key point. Brief Answer to questions. (FIXME)&quot; --- FIXME {% include links.md %} The material between the first and second instances of --- is called the YAML header. The information stored in the YAML header is used by the lesson template to populate important parts of the lesson webpage. This section explains each component of the YAML header and what that information is used for. For each episode, you will need to create a copy of this file and: Replace Introduction with the episode title (not the lesson title) in quotation marks. The episode title will appear on the episode page and in the schedule that appears on the lesson homepage. Enter an estimated number of minutes for teaching the episode and an estimated number of minutes for learners to spend completing challenge problems (including class discussion of challenge solutions). These time estimates will likely be updated by Instructors as they get real-world data on how learners respond to the pacing of the episodes, but it is useful to have a starting point to benchmark from. The lesson template creates a schedule from these time estimates and places it on the lesson homepage. Replace Key question (FIXME) with 1-3 motivating questions for the episode, each on a new line and in quotation marks. These motivating questions will appear in the schedule on the lesson homepage. Replace First learning objective. (FIXME) with 3-7 learning objectives for the episode, each on a new line and in quotation marks. For information on writing useful learning objectives, see the Developing Content chapter. Replace First key point. Brief Answer to questions. (FIXME) with 3-7 major take-aways from the episode. For information on how to distill an episode’s key points, see the Developing Content chapter. Key points for all episodes are shown together in the lesson’s reference page. 6.2.2.2 Episode content After the YAML header, your episode file will contain the content for that episode. This content will likely include: * paragraphs of text * lists * tables * images or figures * code chunks * special blockquotes, including exercises and solutions (described below) This content will be written in Markdown, a light-weight markup language that makes it possible to create fancy HTML pages using only a few formating tricks. In this section, we’ll cover only the Markdown syntax that you will need in order to create the content types listed above. You can find more information about Markdown at https://commonmark.org/help/. Paragraphs of text - To create text paragraphs in Markdown, just type as you normally would! A few neat tricks: surround text with a single pair of stars (*) to make text italic (*italic*) use a double pair of stars to make text bold (**bold**) create headers by starting a line of text with two hash signs (##) There are lots of other fancy things you can do, but this should get you started! Lists - To create a numbered list in Markdown, do this: 1. A 1. numbered 1. list This will show up like this: 1. A 1. numbered 1. list Hint: You can use sequential numbers if you want, but it’s easier to update the list later if you use only 1s. Markdown will create the sequence for you. To create an un-numbered list in Markdown, do this: * An * unnumbered * list This will show up like this: * An * unnumbered * list Tables - To insert a small table into your episode, do this: | Category | Item | |--------- | ---- | | Food | Sandwich | | Drink | Tea | | Food | Apple | This will show up like this: Category Item Food Sandwich Drink Tea Food Apple Images or figures - Place a copy of the image you would like to display into the fig directory. You can then link to the figure using the syntax: ![Figure Description](../fig/figure_file_name.svg) Note about alt text. Question: Is this the “proper” way to insert a figure link? Code chunks - As discussed in an earlier chapter, Carpentries workshops are taught using participatory live coding. Instructors type the code as they teach it and learners type along with the Instructor. For more information about how live coding works, and what its advantages and disadvantages are, read that section of our Instructor Training program. The fact that Carpentries workshops are taught using live coding means that much of your episode content will be code chunks - short blocks of code that learners type along with the Instructor and evaluate on their own machines. Each code chunk should correspond to one interactive session. If learners will be running the code as two distinct commands, that code should be displayed as two distinct chunks in the episode file. You can add a code chunk to your episode using the following syntax: ~~~ pwd ~~~ {: .source} Which will show up like: pwd Code chunks that learners should type out with the Instructor should use the {: .source} tag as shown above. Chunks that show expected output should use the {: .output} tag. Chunks that show an expected error message should use the {: .error} tag. The generic {: .source} tag can be used for all programming languages. To make your code more stylish, you can use a language-specific tag (instead of {: .source}). This will add things like syntax highlighting to your code. The language-specific tags available with our lesson template are: {: .language-bash} {: .html} {: .language-make} {: .language-matlab} {: .language-python} {: .language-r} {: .language-sql} You don’t need to use these language-specific tags, but they make your lesson a little prettier. Special blockquotes - Exercises, solutions, helpful tips, and a few other types of special information are formatted as blockquotes within the episode file. Each blockquote has the same general structure, but ends with a different tag. The ending tag determines how the blockquote will appear on the lesson webpage. The general structure of a blockquote is: &gt; ## Title &gt; &gt; text &gt; text &gt; text {: .callout} where the {: .callout} tag should be replaced with one of the following as appropriate: {: .callout} for sharing an aside or comment. Use sparingly. {: .challenge} for an exercise. {: .discussion} for a discussion question. {: .solution} for an exercise solution. Additional blockquote tags included in our lesson template are described in APPENDIX, however, the four listed above should cover all normal use cases for a lesson author. Exercise solutions are nested within the blockquote for that exercise, as shown below: &gt; ## Challenge Title &gt; &gt; This is the body of the challenge. &gt; &gt; &gt; ## Solution &gt; &gt; &gt; &gt; This is the body of the solution. &gt; {: .solution} {: .challenge} Code chunks may also be nested within blockquotes as needed. 6.2.3 Extras So far we’ve covered how to create and format the content of your lesson homepage (in the index.md file) and your lesson episodes (in multiple .md files within the _episodes directory). This covers most of the files you will need to work with when you create a new lesson. There are a few remaining files that you will need to populate in order for your lesson to be fully fleshed out and ready to teach: The Reference page (reference.md) - this file will be created automatically and will include a list of all of the keypoints that you defined in your episode YAML headers. You don’t need to do anything to create this list! However, it’s a good idea to add a glossary of terms that are used in your lesson. The Setup page (setup.md) - this file will be created automatically, but needs to be populated with installation instructions for software learners will need to have before begining the lesson. If learners are expected to download data prior to the workshop, that data should also be linked and described here. The setup page may be quite simple or more complex, but should always include installation information for all three major platforms (Windows, Unix/MacOS, Linux). The Instructors’ Guide (_extras/guide.md) - this file should provide additional discussion useful to instructors, but not appropriate for inclusion in the main lessons. Remember not to overload on details, and to keep the information here positive and useful for instructors! This guide should include the following sections: Lesson motivation and learning objectives - These concepts should be highlighted in the main lesson material, but ideas for explaining these concepts further can be placed here. Lesson design - Most lessons contain more material than can be taught in a single workshop. Describe a general narrative (with time estimates) for teaching either a half day or full day with this lesson material. You may also choose to include multiple options for lesson design, or what material can be skipped while teaching. This section may also include recommendations for how this lesson fits into the overall workshop. Technical tips and tricks - Provide information on setting up your environment for learners to view your live coding (increasing text size, changing text color, etc), as well as general recommendations for working with coding tools to best suit the learning environment. Common problems - This can include answers to common learner questions, as well as links to resources (blog posts, stack overflow answers, etc) that may solve problems that may occur during a workshop. 6.2.4 Other information In addition to populating the lesson homepage, lesson content (episodes), Instructors’ guide, and other lesson-specific pages, lesson authors need to make a few changes to the template files to make sure that the lesson has all of the neccessary information. In the _config.yml file, set the carpentry variable to the appropriate lesson program, set title to be the overall title for your lesson, set email to the correct contact email for your lesson. In the CONTRIBUTING.md file, change the issues and repo links to match the URLs of your lesson. In the CITATION file, add information about how to cite your lesson. The AUTHORS file should include a list of the lesson’s authors. 6.2.5 Special notes on RMarkdown 6.3 Working on GitHub GitHub is a web-based service for hosting code under version control. In addition to being a technical platform, GitHub is also a social media platform and has its own standards around etiquite and interaction. This section describes how The Carpentries community tends to interact on GitHub and gives you some tips for navigating this new social scene. All Carpentries lesson materials, whether they are established or in early development, are hosted publically on GitHub in one of several organisations. The following high-level organisations are managed by The Carpentries: carpentries - hosts The Carpentries website and materials for programs that span individual lesson programs, such as our Instructor Training curriculum and The Carpentries Handbook datacarpentry - hosts Data Carpentry specific lesson materials and website librarycarpentry - hosts Library Carpentry specific lesson materials and website swcarpentry - hosts Software Carpentry specific lesson materials and website data-lessons - hosts lessons in development which are targeted to become part of the official Carpentries lesson stack carpentrieslab - community-developed lessons which may or may not become part of the official Carpentries lesson stack In order to contribute to lesson materials, you will need a GitHub account. To manage changes, we follow [GitHub flow][github-flow]. Each lesson has two maintainers who review issues and pull requests or encourage others to do so. The maintainers are community volunteers and have final say over what gets merged into the lesson. To use the web interface for contributing to a lesson: Fork the originating repository to your GitHub account. Within your version of the forked repository, move to the default branch (e.g. gh-pages) and create a new branch for each significant change being made. Navigate to the file(s) you wish to change within the new branches and make revisions as required. Commit all changed files within the appropriate branches. Create individual pull requests from each of your changed branches to the gh-pages branch within the originating repository. If you receive feedback, make changes using your issue-specific branches of the forked repository and the pull requests will update automatically. Repeat as needed until all feedback has been addressed. When starting work, please make sure your clone of the originating gh-pages branch is up-to-date before creating your own revision-specific branch(es) from there. Additionally, please only work from your newly-created branch(es) and not your clone of the originating gh-pages branch. Lastly, published copies of all the lessons are available in the gh-pages branch of the originating repository for reference while revising. If you choose to contribute via GitHub, you may want to look at [How to Contribute to an Open Source Project on GitHub][how-contribute]. Creating new lesson or working with existing lesson "],
["the-lesson-life-cycle.html", "Chapter 7 The lesson life-cycle 7.1 Overview 7.2 Pathway for community-developed lessons", " Chapter 7 The lesson life-cycle Definitions of alpha, beta, 1.0 Alpha: The stage that it is in the first time it is taught. (in house) Beta: The stage that it is in after the pilots and clean-up. (wider community) pre-release: The stage that it is in after initial publication. (anyone) stable: Announcements letting the community know that the lesson is being prepared for release and what that means Advertising for Bug BBQ Bug BBQ How to organize for, how to schedule Communications (when and how to announce) Prep (communicating with maintainers about the process) Facilitating communications during the actual event (real time communications, issue assignments, avoiding duplication of work) Clean-up (maintainers, staff, authors) Lesson release checklist Pre-Release Release How to communicate about a release How to do the release in Zenodo Move on website to different category 7.1 Overview Community-developed lessons Lessons with grant support 7.2 Pathway for community-developed lessons Overview of the lesson release timeline If you have an idea for a lesson that would be a good fit for The Carpentries, you first need to check if there are not already existing efforts to develop lessons on the same topic that you could join. The first draft (Pre-Alpha) of a lesson is usally written by an individual or a small group of people. From this first draft, the original authors organize a pilot workshop, and improve the content of the lessons based on the feedback from learners and co-instructors. They go through this iterative process a few times to bring the lesson where it is ready to be peer-reviewed by members of The Carpentries. After that, the lesson should be developed enough that people not involved in initial development efforts can teach it and contribute to it (Beta). After about six months in this stage, the lesson is mature enough and documented enough so that anyone interested can teach it and is officially released. The Pre-Alpha and Alpha development stages should focus on the content of the lesson: What to teach? How to teach it (which exercises, in which order should the concepts be introduced)? In the Beta stage, development efforts should focus on documenting the lesson, so that any Instructor familiar with the concepts covered in the lesson can understand the design of the lesson. 7.2.1 The blueprint (lesson proposal) If you have an idea for a lesson you think would be appropriate for The Carpentries, submit a proposal to the proposals repository in the Carpentries Lab organization following our template. The Curriculum Development Team will assess the fit of the proposed lesson, check for possible overlap with other efforts, and assign an Editor. If you have questions before submitting your proposal you may contact the Curriculum Development Team. The Curriculum Development Team and the Editor will work with you on your proposal. Once your proposal is accepted, we will publish the revised version of your proposal on The Carpentries websites. Community members who wish to join the proposal or support it in other ways will be able do so. The Editor for your lesson will provide guidance during the lesson development process, answer questions that may arise during the development, and coordinate the review process for your lesson. 7.2.2 The assembly (Early development, “Pre-Alpha”) We will create or transfer your repository to the GitHub Carpentries Lab organization where you will develop your lesson. We will provide you with our lesson template, and you will follow The Carpentries lesson development guidelines. During this initial development stage, your lesson will be in the “Pre-Alpha” stage. As lesson development progresses, you will report monthly to the Editor for your lesson. You will work with your handling Editor to set a date to teach the lesson for the first time. The Editor will provide general feedback on the content and structure of the lesson, and ensure that it is ready to be taught. 7.2.3 The sanding (field test, “Alpha”) Once the lesson is ready to be taught for the first time, it will enter the “Alpha” stage. Field-testing a lesson is a good opportunity to receive and incorporate feedback from learners, Instructors, and Developers who can compare their expectations to the reality. The initial feedback gathered during the first time a lesson is taught is really important. The Carpentries Assessment Team will work with you to develop surveys to gather feedback from your learners, helpers, and instructors. The Curriculum Development Team and the Editor for the lesson will review the feedback with you, and help you decide how to incorporate this feedback in your lesson. The Carpentries Community Manager will make an announcement that a new “Alpha” lesson is available to contribute to and can be taught by instructors interested in early-adoption of the lesson. These early workshops are also a good time for Instructors not involved in the development process to teach these lessons. They can provide a fresh perspective and useful feedback on the content of the lessons. After a few iterations of teaching and integrating feedback (and at least 2 early workshop pilots), you will let the Carpentries Editor know that your lesson is ready to be reviewed. The Editor will select 2-3 reviewers within The Carpentries community with teaching experience and/or appropriate domain expertise, who will provide an open and friendly review of the lesson. After incorporating feedback and comments from the reviewers, your lesson will be badged “Reviewed by the Carpentries Community” and will be listed on our websites as such. During this process, you will have the possibility to include a short paper describing your lesson in the GitHub repository and have your lesson considered for publication in JOSE, the Journal of Open Science Education. Once your lesson has gone through the peer-review process and has been approved by the Editor, we will create an official Zenodo release for it, and the lesson will enter the “Beta” stage. 7.2.4 The polishing (“Beta”) The “Beta” stage lasts approximately 6 months. During this time, members of The Carpentries community can teach it and contribute to the content of the lesson. Around the 4th month in this stage, you will organize a “Lesson Polishing” event (aka Bug BBQ). The main goal of this phase of the lesson development is to develop the documentation needed to ensure that people who have not contributed to the initial development efforts of the lesson have enough information to teach it effectively. After a final check from one of The Carpentries’ Editors, we will create a stable release for the lesson that will be listed on our website. Anyone in our community, including local Carpentries communities, will be able to use the lesson in their workshops or meetups. 7.2.5 The stable lesson T We will generate new releases every 6 months. "],
["pilots-and-feedback.html", "Chapter 8 Pilots and Feedback", " Chapter 8 Pilots and Feedback How to run a pilot? How to recruit people to run a pilot? Feedback from pilot transformed into issues and PRs Clean-up (authors and staff) We now have the beta version "],
["from-pre-release-to-stable.html", "Chapter 9 From pre-release to stable", " Chapter 9 From pre-release to stable Workshops Organizing workshops at different institutions (staff assist) Staff make sure a certain number of workshops get organized Use responses from community form to choose institutions Communicating about the costs of these workshops Clean-up based on feedback staff works with maintainers and authors to put in these issues and convert to PRs Communication point with maintainers about release deadline and what needs to be done before then Dedicated time from staff to be available on slack to help maintainers go through issues and review prs Release "],
["maintenance.html", "Chapter 10 Maintenance", " Chapter 10 Maintenance How often to do releases Maintenance releases, as needed but at least every 3 months Big releases, once a year How to coordinate lesson releases How to communicate with Maintainers and community about lesson releases How to split development and production How to welcome and onboard new contributors, contributor guidelines "],
["the-lesson-proposal.html", "A The Lesson Proposal A.1 For all lessons A.2 For Grant-Supported lessons A.3 Transition to officially supported lesson", " A The Lesson Proposal A.1 For all lessons A short description – It should be less than 200 characters and capture the type of data and general audience for the lesson (e.g., “Tabular Data for Phylogeneticsts”, or “Data Managemnet for Digital Humanities”.) The intended audience – Who is the target audience for this lesson? (e.g. Graduate-level researchers in ecology). Duration of the lesson – How long is this lesson? 1.5, 3, 6, or 12 hours. Fit with existing Carpentries lesson – Could this lesson be added or be swapped with an existing lesson in our existing curriculum (e.g., a proposed lesson on Rmarkdown, using the Ecology dataset, could replace the episode on interacting with databases). Tools used – Describe the software, packages, libraries that will be taught in the lesson. Make it clear if any of them are not open source licensed (i.e., they are not listed on the Open Source Initiative website). Suggestions for the dataset to use – review our dataset recommendations and describe the datasets you would like to use if it’s not one that is already in use in our lessons. A brief lesson outline – For each half day of material, please describe: 3–6 concrete learning objectives. An end-of-lesson assessment exercise to demonstrate the skills participants have learned. A summary of the tools and data set(s) that will be used. A point-form learning plan A brief comparison with existing open-access lessons on the subject. Evidence of need – Summarize evidence that researchers need this lesson. This summary may include links to online discussions (mailing lists, twitter, etc) or publications (e.g., descriptions of practices that are not yet widely adopted), results of surveys, etc. Development Team – Who are the people involved? Are they certified Carpentries instructors? What is their experience developing teaching materials in general and for the Carpentries in particular? Development Plan and Timeline – The development plan must include a timeline that makes specific people responsible for specific lesson modules, commitments from specific sites to teach trial versions of the lesson, a date and location for a hackathon (if appropriate), etc. We recognize that this plan may change as lesson development progress, but the more specific it is, the more credible the proposal will be. Support – Explain who will support lesson development and how. If you have secured funding, attach details. If you have not, but intend to seek it, describe any planned or submitted funding requests. If the work is not being funded, explain how development and delivery will be supported. A.2 For Grant-Supported lessons A.3 Transition to officially supported lesson "]
]
